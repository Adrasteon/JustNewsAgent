"""
from common.observability import get_logger
Advanced Performance Optimization Recommendation Engine

Provides sophisticated optimization recommendations based on:
- Multi-dimensional performance analysis
- Predictive modeling for resource allocation
- Automated bottleneck resolution strategies
- Learning-based optimization suggestions
- Real-time adaptation recommendations
"""


import time
from collections import defaultdict, deque
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
from typing import Any

logger = get_logger(__name__)

class OptimizationPriority(Enum):
    """Priority levels for optimization recommendations"""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"

class OptimizationCategory(Enum):
    """Categories of optimization recommendations"""
    MEMORY = "memory"
    COMPUTE = "compute"
    BATCH_SIZE = "batch_size"
    MODEL_OPTIMIZATION = "model_optimization"
    RESOURCE_ALLOCATION = "resource_allocation"
    SYSTEM_CONFIGURATION = "system_configuration"

@dataclass
class OptimizationRecommendation:
    """Detailed optimization recommendation"""
    id: str
    category: OptimizationCategory
    priority: OptimizationPriority
    title: str
    description: str
    impact_score: float  # Expected performance improvement (0-100)
    confidence_score: float  # Confidence in recommendation (0-100)
    implementation_complexity: str  # "low", "medium", "high"
    estimated_time_savings: float  # Expected time savings in seconds per operation
    affected_agents: list[str]
    prerequisites: list[str]
    implementation_steps: list[str]
    rollback_steps: list[str]
    created_at: datetime
    expires_at: datetime | None = None

@dataclass
class PerformancePattern:
    """Performance pattern analysis"""
    pattern_type: str
    frequency: int
    avg_impact: float
    trend_direction: str  # "improving", "degrading", "stable"
    confidence: float
    last_observed: datetime

class AdvancedOptimizationEngine:
    """
    Advanced optimization recommendation engine with predictive analytics

    Features:
    - Multi-dimensional performance analysis
    - Predictive modeling for optimization
    - Automated bottleneck resolution
    - Learning-based recommendations
    - Real-time adaptation strategies
    """

    def __init__(self, analytics_engine=None):
        self.analytics_engine = analytics_engine
        self.recommendations: dict[str, OptimizationRecommendation] = {}
        self.performance_patterns: dict[str, PerformancePattern] = {}
        self.optimization_history: deque = deque(maxlen=1000)

        # Analysis parameters
        self.analysis_window_hours = 24
        self.min_samples_for_analysis = 10
        self.confidence_threshold = 0.7

        # Learning data
        self.recommendation_effectiveness = defaultdict(list)
        self.pattern_correlations = defaultdict(dict)

        logger.info("ðŸš€ Advanced Optimization Engine initialized")

    def analyze_and_recommend(self, hours: int = 24) -> list[OptimizationRecommendation]:
        """
        Perform comprehensive analysis and generate optimization recommendations

        Args:
            hours: Analysis window in hours

        Returns:
            List of prioritized optimization recommendations
        """
        try:
            # Get comprehensive analytics data
            analytics = self.analytics_engine.get_real_time_analytics(hours)
            agent_profiles = {}

            # Get detailed profiles for all agents
            for agent_name in ["scout", "analyst", "synthesizer", "fact_checker", "newsreader", "memory"]:
                profile = self.analytics_engine.get_agent_performance_profile(agent_name, hours)
                if "error" not in profile:
                    agent_profiles[agent_name] = profile

            # Perform multi-dimensional analysis
            recommendations = []

            # Memory optimization analysis
            recommendations.extend(self._analyze_memory_optimization(analytics, agent_profiles))

            # Compute optimization analysis
            recommendations.extend(self._analyze_compute_optimization(analytics, agent_profiles))

            # Batch size optimization analysis
            recommendations.extend(self._analyze_batch_size_optimization(analytics, agent_profiles))

            # Model optimization analysis
            recommendations.extend(self._analyze_model_optimization(analytics, agent_profiles))

            # Resource allocation optimization
            recommendations.extend(self._analyze_resource_allocation(analytics, agent_profiles))

            # System configuration optimization
            recommendations.extend(self._analyze_system_configuration(analytics, agent_profiles))

            # Filter and prioritize recommendations
            filtered_recommendations = self._filter_and_prioritize(recommendations)

            # Update recommendation history
            for rec in filtered_recommendations:
                self.recommendations[rec.id] = rec
                self.optimization_history.append({
                    'timestamp': datetime.now(),
                    'recommendation_id': rec.id,
                    'category': rec.category.value,
                    'priority': rec.priority.value,
                    'impact_score': rec.impact_score
                })

            return filtered_recommendations

        except Exception as e:
            logger.error(f"Error in optimization analysis: {e}")
            return []

    def _analyze_memory_optimization(self, analytics, agent_profiles) -> list[OptimizationRecommendation]:
        """Analyze memory usage patterns and generate optimization recommendations"""
        recommendations = []

        try:
            # Check for memory pressure
            if analytics.peak_gpu_memory_mb > 20000:  # Over 20GB on RTX3090
                recommendations.append(OptimizationRecommendation(
                    id=f"memory_reduction_{int(time.time())}",
                    category=OptimizationCategory.MEMORY,
                    priority=OptimizationPriority.CRITICAL,
                    title="Reduce Memory Pressure",
                    description="High memory usage detected. Implement memory optimization strategies.",
                    impact_score=85.0,
                    confidence_score=90.0,
                    implementation_complexity="medium",
                    estimated_time_savings=2.5,
                    affected_agents=list(agent_profiles.keys()),
                    prerequisites=["GPU monitoring enabled", "Model quantization support"],
                    implementation_steps=[
                        "Enable gradient checkpointing for large models",
                        "Implement model offloading for unused layers",
                        "Reduce batch sizes for memory-intensive operations",
                        "Enable memory defragmentation"
                    ],
                    rollback_steps=[
                        "Disable gradient checkpointing",
                        "Restore original batch sizes",
                        "Disable memory defragmentation"
                    ],
                    created_at=datetime.now()
                ))

            # Check for memory fragmentation
            memory_efficiency = analytics.avg_gpu_utilization_pct / (analytics.peak_gpu_memory_mb / 24000 * 100) if analytics.peak_gpu_memory_mb > 0 else 0
            if memory_efficiency < 0.6:  # Less than 60% memory efficiency
                recommendations.append(OptimizationRecommendation(
                    id=f"memory_fragmentation_{int(time.time())}",
                    category=OptimizationCategory.MEMORY,
                    priority=OptimizationPriority.HIGH,
                    title="Optimize Memory Fragmentation",
                    description="Memory fragmentation detected. Reorganize memory allocation patterns.",
                    impact_score=65.0,
                    confidence_score=75.0,
                    implementation_complexity="low",
                    estimated_time_savings=1.2,
                    affected_agents=list(agent_profiles.keys()),
                    prerequisites=["PyTorch memory management"],
                    implementation_steps=[
                        "Enable CUDA memory coalescing",
                        "Implement memory pool optimization",
                        "Use pinned memory for frequent allocations",
                        "Enable memory defragmentation routines"
                    ],
                    rollback_steps=[
                        "Disable memory coalescing",
                        "Restore default memory allocation"
                    ],
                    created_at=datetime.now()
                ))

        except Exception as e:
            logger.error(f"Error in memory optimization analysis: {e}")

        return recommendations

    def _analyze_compute_optimization(self, analytics, agent_profiles) -> list[OptimizationRecommendation]:
        """Analyze compute utilization and generate optimization recommendations"""
        recommendations = []

        try:
            # Check for low GPU utilization
            if analytics.avg_gpu_utilization_pct < 50:
                recommendations.append(OptimizationRecommendation(
                    id=f"compute_utilization_{int(time.time())}",
                    category=OptimizationCategory.COMPUTE,
                    priority=OptimizationPriority.HIGH,
                    title="Improve GPU Utilization",
                    description="GPU utilization is below optimal levels. Optimize compute resource usage.",
                    impact_score=70.0,
                    confidence_score=80.0,
                    implementation_complexity="medium",
                    estimated_time_savings=1.8,
                    affected_agents=list(agent_profiles.keys()),
                    prerequisites=["GPU monitoring enabled", "Batch processing support"],
                    implementation_steps=[
                        "Increase batch sizes for compute-bound operations",
                        "Implement concurrent kernel execution",
                        "Optimize data transfer patterns",
                        "Enable GPU stream parallelism"
                    ],
                    rollback_steps=[
                        "Restore original batch sizes",
                        "Disable concurrent execution"
                    ],
                    created_at=datetime.now()
                ))

            # Check for compute bottlenecks
            if analytics.avg_processing_time_s > 3.0:  # Over 3 seconds average
                recommendations.append(OptimizationRecommendation(
                    id=f"compute_bottleneck_{int(time.time())}",
                    category=OptimizationCategory.COMPUTE,
                    priority=OptimizationPriority.CRITICAL,
                    title="Resolve Compute Bottlenecks",
                    description="Compute performance bottlenecks detected. Optimize processing pipeline.",
                    impact_score=80.0,
                    confidence_score=85.0,
                    implementation_complexity="high",
                    estimated_time_savings=3.0,
                    affected_agents=list(agent_profiles.keys()),
                    prerequisites=["Performance profiling enabled", "CUDA optimization tools"],
                    implementation_steps=[
                        "Profile kernel execution times",
                        "Optimize memory access patterns",
                        "Implement kernel fusion where possible",
                        "Use TensorRT for inference optimization",
                        "Enable mixed precision computing"
                    ],
                    rollback_steps=[
                        "Restore original kernel implementations",
                        "Disable mixed precision"
                    ],
                    created_at=datetime.now()
                ))

        except Exception as e:
            logger.error(f"Error in compute optimization analysis: {e}")

        return recommendations

    def _analyze_batch_size_optimization(self, analytics, agent_profiles) -> list[OptimizationRecommendation]:
        """Analyze batch size efficiency and generate optimization recommendations"""
        recommendations = []

        try:
            # Analyze batch size efficiency across agents
            for agent_name, profile in agent_profiles.items():
                if 'performance_stats' in profile:
                    stats = profile['performance_stats']

                    # Check if batch size is too small
                    if stats.get('avg_throughput_items_per_s', 0) < 10:
                        recommendations.append(OptimizationRecommendation(
                            id=f"batch_size_{agent_name}_{int(time.time())}",
                            category=OptimizationCategory.BATCH_SIZE,
                            priority=OptimizationPriority.MEDIUM,
                            title=f"Optimize Batch Size for {agent_name}",
                            description=f"Batch size for {agent_name} may be suboptimal. Analyze and optimize.",
                            impact_score=55.0,
                            confidence_score=70.0,
                            implementation_complexity="low",
                            estimated_time_savings=0.8,
                            affected_agents=[agent_name],
                            prerequisites=["GPU optimizer enabled"],
                            implementation_steps=[
                                f"Analyze {agent_name} performance with different batch sizes",
                                "Identify optimal batch size using GPU optimizer",
                                f"Update {agent_name} configuration with optimal batch size",
                                "Monitor performance improvement"
                            ],
                            rollback_steps=[
                                f"Restore original batch size for {agent_name}"
                            ],
                            created_at=datetime.now()
                        ))

        except Exception as e:
            logger.error(f"Error in batch size optimization analysis: {e}")

        return recommendations

    def _analyze_model_optimization(self, analytics, agent_profiles) -> list[OptimizationRecommendation]:
        """Analyze model performance and generate optimization recommendations"""
        recommendations = []

        try:
            # Check for model-specific optimizations
            if analytics.success_rate_pct < 95:
                recommendations.append(OptimizationRecommendation(
                    id=f"model_optimization_{int(time.time())}",
                    category=OptimizationCategory.MODEL_OPTIMIZATION,
                    priority=OptimizationPriority.HIGH,
                    title="Optimize Model Performance",
                    description="Model performance below optimal levels. Implement model optimizations.",
                    impact_score=75.0,
                    confidence_score=80.0,
                    implementation_complexity="medium",
                    estimated_time_savings=2.2,
                    affected_agents=list(agent_profiles.keys()),
                    prerequisites=["Model optimization tools available"],
                    implementation_steps=[
                        "Enable model quantization (INT8/FP16)",
                        "Implement model pruning for unused parameters",
                        "Use knowledge distillation for smaller models",
                        "Enable dynamic batching for variable inputs",
                        "Implement model caching for frequently used models"
                    ],
                    rollback_steps=[
                        "Disable quantization",
                        "Restore original model weights",
                        "Disable dynamic batching"
                    ],
                    created_at=datetime.now()
                ))

        except Exception as e:
            logger.error(f"Error in model optimization analysis: {e}")

        return recommendations

    def _analyze_resource_allocation(self, analytics, agent_profiles) -> list[OptimizationRecommendation]:
        """Analyze resource allocation patterns and generate optimization recommendations"""
        recommendations = []

        try:
            # Check for resource allocation inefficiencies
            total_memory_allocated = sum(
                profile.get('performance_stats', {}).get('peak_memory_mb', 0)
                for profile in agent_profiles.values()
            )

            if total_memory_allocated > 20000:  # Over 20GB total allocation
                recommendations.append(OptimizationRecommendation(
                    id=f"resource_allocation_{int(time.time())}",
                    category=OptimizationCategory.RESOURCE_ALLOCATION,
                    priority=OptimizationPriority.MEDIUM,
                    title="Optimize Resource Allocation",
                    description="Resource allocation patterns can be optimized for better efficiency.",
                    impact_score=60.0,
                    confidence_score=75.0,
                    implementation_complexity="medium",
                    estimated_time_savings=1.5,
                    affected_agents=list(agent_profiles.keys()),
                    prerequisites=["GPU manager enabled", "Resource monitoring"],
                    implementation_steps=[
                        "Analyze resource usage patterns across agents",
                        "Implement dynamic resource allocation",
                        "Enable resource sharing between compatible operations",
                        "Optimize memory allocation strategies",
                        "Implement resource usage forecasting"
                    ],
                    rollback_steps=[
                        "Restore static resource allocation",
                        "Disable resource sharing"
                    ],
                    created_at=datetime.now()
                ))

        except Exception as e:
            logger.error(f"Error in resource allocation analysis: {e}")

        return recommendations

    def _analyze_system_configuration(self, analytics, agent_profiles) -> list[OptimizationRecommendation]:
        """Analyze system configuration and generate optimization recommendations"""
        recommendations = []

        try:
            # Check for system-level optimizations
            if analytics.avg_gpu_utilization_pct < 70 and analytics.peak_gpu_memory_mb < 15000:
                recommendations.append(OptimizationRecommendation(
                    id=f"system_config_{int(time.time())}",
                    category=OptimizationCategory.SYSTEM_CONFIGURATION,
                    priority=OptimizationPriority.LOW,
                    title="System Configuration Optimization",
                    description="System configuration can be optimized for better performance.",
                    impact_score=45.0,
                    confidence_score=65.0,
                    implementation_complexity="low",
                    estimated_time_savings=0.5,
                    affected_agents=list(agent_profiles.keys()),
                    prerequisites=["System administration access"],
                    implementation_steps=[
                        "Optimize CUDA thread block sizes",
                        "Configure GPU clock speeds for performance",
                        "Enable GPU persistence mode",
                        "Optimize system memory allocation",
                        "Configure NUMA settings for GPU affinity"
                    ],
                    rollback_steps=[
                        "Restore default CUDA settings",
                        "Disable GPU persistence mode"
                    ],
                    created_at=datetime.now()
                ))

        except Exception as e:
            logger.error(f"Error in system configuration analysis: {e}")

        return recommendations

    def _filter_and_prioritize(self, recommendations: list[OptimizationRecommendation]) -> list[OptimizationRecommendation]:
        """Filter and prioritize optimization recommendations"""
        try:
            # Remove duplicates based on category and affected agents
            seen = set()
            unique_recommendations = []

            for rec in recommendations:
                key = (rec.category.value, tuple(sorted(rec.affected_agents)))
                if key not in seen:
                    seen.add(key)
                    unique_recommendations.append(rec)

            # Sort by priority and impact score
            priority_order = {
                OptimizationPriority.CRITICAL: 4,
                OptimizationPriority.HIGH: 3,
                OptimizationPriority.MEDIUM: 2,
                OptimizationPriority.LOW: 1
            }

            sorted_recommendations = sorted(
                unique_recommendations,
                key=lambda x: (priority_order[x.priority], x.impact_score),
                reverse=True
            )

            # Limit to top recommendations
            return sorted_recommendations[:10]

        except Exception as e:
            logger.error(f"Error in recommendation filtering: {e}")
            return recommendations[:5] if recommendations else []

    def get_recommendation_history(self, hours: int = 24) -> list[dict[str, Any]]:
        """Get historical optimization recommendations"""
        cutoff_time = datetime.now() - timedelta(hours=hours)
        return [
            rec for rec in self.optimization_history
            if rec['timestamp'] > cutoff_time
        ]

    def track_recommendation_effectiveness(self, recommendation_id: str, effectiveness_score: float):
        """Track the effectiveness of implemented recommendations"""
        if recommendation_id in self.recommendations:
            self.recommendation_effectiveness[recommendation_id].append({
                'score': effectiveness_score,
                'timestamp': datetime.now()
            })

    def get_optimization_insights(self) -> dict[str, Any]:
        """Get comprehensive optimization insights"""
        try:
            recent_recommendations = self.get_recommendation_history(24)

            insights = {
                'total_recommendations_generated': len(recent_recommendations),
                'recommendations_by_category': defaultdict(int),
                'recommendations_by_priority': defaultdict(int),
                'average_impact_score': 0.0,
                'most_common_category': None,
                'optimization_trends': []
            }

            if recent_recommendations:
                total_impact = 0
                for rec in recent_recommendations:
                    insights['recommendations_by_category'][rec['category']] += 1
                    insights['recommendations_by_priority'][rec.get('priority', 'unknown')] += 1
                    total_impact += rec.get('impact_score', 0)

                insights['average_impact_score'] = total_impact / len(recent_recommendations)
                insights['most_common_category'] = max(
                    insights['recommendations_by_category'].keys(),
                    key=lambda x: insights['recommendations_by_category'][x]
                )

            return insights

        except Exception as e:
            logger.error(f"Error generating optimization insights: {e}")
            return {'error': str(e)}

# Global optimization engine instance
_optimization_engine: AdvancedOptimizationEngine | None = None

def get_optimization_engine(analytics_engine=None) -> AdvancedOptimizationEngine:
    """Get the global optimization engine instance"""
    global _optimization_engine
    if _optimization_engine is None:
        _optimization_engine = AdvancedOptimizationEngine(analytics_engine)
    return _optimization_engine

def generate_optimization_recommendations(hours: int = 24) -> list[OptimizationRecommendation]:
    """Generate optimization recommendations for the specified time period"""
    from ..common.advanced_analytics import get_analytics_engine

    analytics_engine = get_analytics_engine()
    optimization_engine = get_optimization_engine(analytics_engine)

    return optimization_engine.analyze_and_recommend(hours)

def get_optimization_insights() -> dict[str, Any]:
    """Get comprehensive optimization insights"""
    optimization_engine = get_optimization_engine()
    return optimization_engine.get_optimization_insights()
