name: CI - JustNewsAgent Tests

# Run on manual dispatch and pull requests to main/dev branches
on:
  workflow_dispatch:
    inputs:
      run_parity:
        description: 'Run parity-e2e job (true|false)'
        required: false
        default: 'false'
  pull_request:
    branches: [ main, dev ]
  push:
    branches: [ main, dev ]

jobs:
  test:
    name: Run tests (conda environment)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Miniconda
        uses: conda-incubator/setup-miniconda@v3
        with:
          python-version: 3.12
          auto-update-conda: true
          activate-environment: justnews-v2-py312
          environment-file: environment.yml
          use-mamba: true

      - name: Install additional dependencies
        shell: bash -l {0}
        run: |
          # Ensure we're in the activated environment
          conda activate justnews-v2-py312

          # Upgrade pip and install any additional requirements
          pip install -U pip setuptools wheel

          # Install requirements.txt dependencies (if not already covered by environment.yml)
          pip install -r requirements.txt

      - name: Run unit tests
        shell: bash -l {0}
        run: |
          conda activate justnews-v2-py312
          # Run unit tests only (exclude integration tests)
          pytest -v -k "not integration" --tb=short --maxfail=5

      - name: Run integration tests (optional)
        shell: bash -l {0}
        run: |
          conda activate justnews-v2-py312
          # Run integration tests if they exist
          pytest -v -k "integration" --tb=short --maxfail=3 || echo "No integration tests found or failed"
        continue-on-error: true

      - name: Generate test coverage report
        shell: bash -l {0}
        run: |
          conda activate justnews-v2-py312
          # Install coverage tools if not present
          pip install pytest-cov coverage

          # Run tests with coverage
          pytest --cov=. --cov-report=xml --cov-report=term -k "not integration"
        continue-on-error: true

      - name: Upload coverage reports
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
        continue-on-error: true

  version-compliance:
    name: Version Compliance Check
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run version compliance validation
        run: |
          python scripts/validate_version_compliance.py

      - name: Run version consistency check
        run: |
          python scripts/validate_versions.py

  parity-e2e:
    name: Parity E2E (Kafka parity generator)
    runs-on: ubuntu-latest
    needs: test
    # Only run parity-e2e when explicitly requested via workflow_dispatch input
    # or when working on branches/PRs that include parity in their name.
    if: >-
      (github.event_name == 'workflow_dispatch' && github.event.inputs.run_parity == 'true') ||
      (github.event_name == 'pull_request' && contains(github.head_ref, 'parity'))
    timeout-minutes: 120
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Docker Compose
        run: |
          set -euo pipefail
          sudo apt-get update
          # Install docker (for docker-compose-plugin) and the plugin; allow failures to avoid hard fail on unexpected apt issues
          sudo apt-get install -y docker.io docker-compose-plugin || true
          # Prefer netcat-openbsd, fall back to netcat-traditional
          if ! sudo apt-get install -y netcat-openbsd; then
            sudo apt-get install -y netcat-traditional || true
          fi
          # Ensure a docker-compose CLI binary is available for scripts that use `docker-compose`
          if ! command -v docker-compose >/dev/null 2>&1; then
            if [ -f /usr/libexec/docker/cli-plugins/docker-compose ]; then
              sudo ln -sf /usr/libexec/docker/cli-plugins/docker-compose /usr/local/bin/docker-compose || true
            elif [ -f /usr/lib/docker/cli-plugins/docker-compose ]; then
              sudo ln -sf /usr/lib/docker/cli-plugins/docker-compose /usr/local/bin/docker-compose || true
            else
              # Fallback: download a standalone docker-compose binary
              DOCKER_COMPOSE_VERSION="2.21.0"
              sudo curl -fsSL -o /usr/local/bin/docker-compose "https://github.com/docker/compose/releases/download/v${DOCKER_COMPOSE_VERSION}/docker-compose-linux-x86_64"
              sudo chmod +x /usr/local/bin/docker-compose || true
            fi
          fi
          # Show version to verify install
          if command -v docker-compose >/dev/null 2>&1; then
            docker-compose --version || true
          else
            docker compose version || true
          fi

      - name: Build CI test image
        run: |
          docker build -t justnews/kafka-ci:latest -f kafka/docker/ci/Dockerfile kafka/

      - name: Prepare host artifact directory
        run: mkdir -p ./tmp/parity

      - name: Bring up Kafka dev stack with retries
        run: |
          docker-compose -p kafka_ci -f kafka/docker/docker-compose.kafka.yml up -d --build
          MAX_RETRIES=120
          for i in $(seq 1 $MAX_RETRIES); do
            echo "readiness: attempt $i/$MAX_RETRIES"
            SR_OK=1
            BROKER_OK=1
            if curl -sSf http://localhost:8081/ >/dev/null 2>&1; then
              SR_OK=0
            fi
            if (echo > /dev/tcp/localhost/9092) >/dev/null 2>&1; then
              BROKER_OK=0
            fi
            if [ "$SR_OK" -eq 0 ] && [ "$BROKER_OK" -eq 0 ]; then
              echo "All services appear ready"
              break
            fi
            sleep $((i < 30 ? i : 30))
          done
          if ! curl -sSf http://localhost:8081/ >/dev/null 2>&1 || ! (echo > /dev/tcp/localhost/9092) >/dev/null 2>&1; then
            echo "Service readiness checks failed; dumping docker-compose ps" >&2
            docker-compose -p kafka_ci -f kafka/docker/docker-compose.kafka.yml ps
            exit 4
          fi

      - name: Kafka admin readiness probe
        run: |
          docker run --rm --network kafka_ci_default \
            -e KAFKA_BOOTSTRAP_SERVERS=broker:9092 \
            justnews/kafka-ci:latest \
            bash -lc "python -m kafka.scripts.kafka_admin_probe"

      - name: Bootstrap topics and schemas
        run: |
          docker run --rm --network kafka_ci_default \
            -e KAFKA_BOOTSTRAP_SERVERS=broker:9092 \
            -e SCHEMA_REGISTRY_URL=http://schema-registry:8081 \
            justnews/kafka-ci:latest \
            bash -lc "python -m kafka.scripts.bootstrap_pilot --bootstrap broker:9092 --registry http://schema-registry:8081 --topics-file kafka/config/topics/pilot_topics.yaml"

      - name: Run parity generator and harness inside CI image (capture exit codes)
        run: |
          set -euo pipefail
          docker run --rm --network kafka_ci_default -v $(pwd)/tmp/parity:/tmp/parity \
            -e KAFKA_BOOTSTRAP_SERVERS=broker:9092 \
            -e SCHEMA_REGISTRY_URL=http://schema-registry:8081 \
            -e PARITY_TOLERANCE=5 \
            justnews/kafka-ci:latest \
            bash -lc '
              set -euo pipefail
              python -m kafka.tests.parity.generate_parity_report --sample kafka/tests/parity/sample_dataset.jsonl --out /tmp/parity --tolerance "$PARITY_TOLERANCE" || echo "GEN_EXIT:$?" > /tmp/parity/gen_exit.txt
              pytest -q kafka/tests/parity/test_parity_harness.py --junitxml=/tmp/parity/parity-junit.xml || echo "PY_EXIT:$?" > /tmp/parity/py_exit.txt
            '
          GEN_EXIT=0
          PY_EXIT=0
          if [ -f ./tmp/parity/gen_exit.txt ]; then
            GEN_EXIT=$(sed -E 's/[^0-9]*([0-9]+).*/\1/' ./tmp/parity/gen_exit.txt || echo 2)
          fi
          if [ -f ./tmp/parity/py_exit.txt ]; then
            PY_EXIT=$(sed -E 's/[^0-9]*([0-9]+).*/\1/' ./tmp/parity/py_exit.txt || echo 1)
          fi
          echo "Parity generator exit code: $GEN_EXIT, pytest exit code: $PY_EXIT"
          if [ "$GEN_EXIT" -ne 0 ] || [ "$PY_EXIT" -ne 0 ]; then
            echo "Parity checks failed: generator=$GEN_EXIT pytest=$PY_EXIT" >&2
            exit $(( GEN_EXIT > PY_EXIT ? GEN_EXIT : PY_EXIT ))
          fi

      - name: Upload parity artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: parity-artifacts
          path: ./tmp/parity
          if-no-files-found: error

      - name: Tear down Kafka stack
        if: always()
        run: docker-compose -p kafka_ci -f kafka/docker/docker-compose.kafka.yml down -v
